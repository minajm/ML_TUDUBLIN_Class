{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first `scikit-learn` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Go-Out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>86</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>56</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Wind_Speed  Go-Out\n",
       "0            6        85          30       0\n",
       "1           14        90          35       0\n",
       "2           15        86           8       1\n",
       "3           21        56          15       1\n",
       "4           17        67           9       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = pd.read_csv('Forecast.csv')\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the `numpy` arrays to use to train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = forecast.pop('Go-Out').values  # target feature\n",
    "X = forecast.values                # training data\n",
    "type(X),type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a *k*-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3) \n",
    "kNN.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up sample test data and use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[8,70,11],\n",
    "                   [8,69,15]])\n",
    "kNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All `sklearn` classifiers implement the `Estimator` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X,y)\n",
    "tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)\n",
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swapping between classifiers (Estimators) makes model selection easy.  \n",
    "Note that each predictor gives different results for the test data examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[1 1]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "cfrs = [kNN,tree,lr]\n",
    "for cfr in cfrs:\n",
    "    cfr.fit(X,y)\n",
    "    print(cfr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "All preprocessing modules implement the `Transformer`  API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.59094327, -0.05406252, -0.79537086],\n",
       "       [-1.59094327, -0.10040182, -0.37117307]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)   # standardise to zero mean and unit variance\n",
    "X_scaled = scaler.transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.125     , 0.6875    , 0.17241379],\n",
       "       [0.125     , 0.675     , 0.31034483]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_scaler = preprocessing.MinMaxScaler()        # standardise to range [0,1]\n",
    "mm_scaler.fit(X)\n",
    "X_scaled = mm_scaler.transform(X)\n",
    "X_test_scaled = mm_scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try It Yourself\n",
    "\n",
    "Using the `penguin_size` dataset, experiment with some of the different models available in *sci-kit learn*. Some examples of what you can try are\n",
    "\n",
    "* [Decision Trees](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "* [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "* [KNN Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "You can try each of the algorithms with and without scalers, and explore the parameters outlined in the SKLearn documentation for each to see what impact it has on the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Data Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB() is 0.5277777777777778\n",
      "Accuracy of LogisticRegression(class_weight='balanced', max_iter=10000) is 0.7222222222222222\n",
      "Accuracy of DecisionTreeClassifier() is 0.4444444444444444\n",
      "Accuracy of KNeighborsClassifier(n_neighbors=3) is 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def encode_features(df):\n",
    "    \"\"\"\n",
    "    Some models (such as the decision tree, for example) don't work with categorical data. This function\n",
    "    goes through each column in the dataframe and uses a label encoder to convert categorical data to numerical.\n",
    "    For example, `Gentoo`, `Emperor`, `Chinstrap` as penguin species would get replaced with 1, 2, 3\n",
    "    \n",
    "    We'll talk more about label encoding and other things to watch out for as the module progresses.\n",
    "    \"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in range(len(df.columns)):\n",
    "        df.iloc[:,i] = le.fit_transform(df.iloc[:,i])\n",
    "    return df\n",
    "\n",
    "penguins_train = pd.read_csv('penguins_train.csv')\n",
    "penguins_test = pd.read_csv('penguins_test.csv')\n",
    "\n",
    "\n",
    "# Preprocessing goes here. Make sure that any preprocessing done to the training data is also done to the test data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "penguins_train = encode_features(penguins_train)\n",
    "penguins_test = encode_features(penguins_test)\n",
    "\n",
    "\n",
    "y_train = penguins_train.pop('species')\n",
    "X_train = penguins_train.values\n",
    "\n",
    "y_test = penguins_test.pop('species')\n",
    "X_test = penguins_test.values\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = [] # the predict(X_test) method on your classifier will return a list of predictions for y_test\n",
    "\n",
    "# # create a classifier\n",
    "# # make sure you `fit` the classifier on the training data before you try to predict\n",
    "\n",
    "\n",
    "# # A handy way to measure the accuracy of your classifier which compares actual targets against predictions\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy is {accuracy}\")\n",
    "\n",
    "classifiers =[]\n",
    "model1 = GaussianNB()\n",
    "classifiers.append(model1)\n",
    "model2 = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "classifiers.append(model2)\n",
    "model3 = DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "model4 = KNeighborsClassifier(n_neighbors=3)\n",
    "classifiers.append(model4)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB() is 0.8055555555555556\n",
      "Accuracy of LogisticRegression(class_weight='balanced', max_iter=10000) is 0.4444444444444444\n",
      "Accuracy of DecisionTreeClassifier() is 0.4444444444444444\n",
      "Accuracy of KNeighborsClassifier(n_neighbors=3) is 0.5277777777777778\n"
     ]
    }
   ],
   "source": [
    "mm_scaler = preprocessing.MinMaxScaler()        # standardise to range [0,1]\n",
    "mm_scaler.fit(X_train)\n",
    "X_train_s = mm_scaler.transform(X_train)\n",
    "X_test_s = mm_scaler.transform(X_test)\n",
    "X_test_s\n",
    "\n",
    "\n",
    "\n",
    "classifiers_s =[]\n",
    "model1 = GaussianNB()\n",
    "classifiers_s.append(model1)\n",
    "model2 = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "classifiers_s.append(model2)\n",
    "model3 = DecisionTreeClassifier()\n",
    "classifiers_s.append(model3)\n",
    "model4 = KNeighborsClassifier(n_neighbors=3)\n",
    "classifiers_s.append(model4)\n",
    "\n",
    "for clf_s in classifiers_s:\n",
    "    clf_s.fit(X_train_s, y_train)\n",
    "    y_pred_s= clf_s.predict(X_test_s)\n",
    "    acc_s = accuracy_score(y_test, y_pred_s)\n",
    "    print(\"Accuracy of %s is %s\"%(clf_s, acc_s)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNB() is 0.8333333333333334\n",
      "Accuracy of LogisticRegression(class_weight='balanced', max_iter=10000) is 0.5833333333333334\n",
      "Accuracy of DecisionTreeClassifier() is 0.4444444444444444\n",
      "Accuracy of KNeighborsClassifier(n_neighbors=3) is 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)   # standardise to zero mean and unit variance\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled\n",
    "\n",
    "classifiers_scaled =[]\n",
    "model1 = GaussianNB()\n",
    "classifiers_scaled.append(model1)\n",
    "model2 = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "classifiers_scaled.append(model2)\n",
    "model3 = DecisionTreeClassifier()\n",
    "classifiers_scaled.append(model3)\n",
    "model4 = KNeighborsClassifier(n_neighbors=3)\n",
    "classifiers_scaled.append(model4)\n",
    "\n",
    "for clf_scaled in classifiers_scaled:\n",
    "    clf_scaled.fit(X_train_scaled, y_train)\n",
    "    y_pred_scaled= clf_scaled.predict(X_test_scaled)\n",
    "    acc_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "    print(\"Accuracy of %s is %s\"%(clf_scaled, acc_scaled)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
